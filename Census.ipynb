{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6286ce69-0029-4e16-b0aa-6524cf494303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from modules.data_preparator import DataPreparator\n",
    "from modules.model_pipeline import MLModelsPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429181c9-8295-4e22-a34e-7db2bce0f462",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b9695-79b1-4686-9293-a2ff8f40719a",
   "metadata": {},
   "source": [
    "Read in the raw data and make some quick preprocessing changes. We need to convert the dependent variable to numeric and replace some anomolous values in the categorical columns (i.e., the ? symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5a083-d144-416e-b909-397f48a93464",
   "metadata": {},
   "source": [
    "These sections are commented out. A hard copy of pre-processed and pre-split datasets in provided in the package. This always anyone to reproduce the results from this tutorial without the randomness from splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0b6ace-aa3d-40dc-bdff-df76967de79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(os.path.join(\"data\", \"census\", \"adult.csv\"))\n",
    "    # # replace the question mark values with missing\n",
    "    # data.replace(to_replace='?', value=np.nan, inplace=True)\n",
    "    # data.replace({'income': {'<=50K': 0, '>50K': 1}}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f29ab-30a9-4c3e-938d-dd1f78be1a5c",
   "metadata": {},
   "source": [
    "## Dataset Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "932d8b3b-40de-4e7d-b4f7-d2be73701454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Dataset paramaters ---- #\n",
    "features = ['workclass', 'fnlwgt', 'education', 'educational-num',\n",
    "            'marital-status', 'occupation', 'relationship',\n",
    "            'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "dep_var = 'income'\n",
    "demo_vars = ['race', 'gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf1cbfb-7fb4-42c9-94d1-cd7a5d8348d6",
   "metadata": {},
   "source": [
    "Below is the code for creating the initial DataHandler class that contains several new features. The DataHandler can now conduct pairwise deletion of missing data, impute values for missing data, take in demogrpahics variables, and encode categorical variables to numeric values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9386d97-460a-4ab2-bea0-e4d19fbd9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # ---- We use this first run to split the data for us, then we save those outputs so that we have a fully\n",
    "    # ---- reproducible datasets. We can comment out this code, because now we will on the pre-saved datasets with\n",
    "    # ---- missing data already removed\n",
    "    # data_prep = DataPreparator(data=data, features=features, dep_var=dep_var, demo_vars=demo_vars, max_miss=None)\n",
    "    # data_prep.split_data(val_set=False, test_size=0.30, random_state=456)\n",
    "    # data_prep.encode_categorical(strategy='TargetEncoder')\n",
    "    # data_prep.x_train.columns\n",
    "    # data_prep.features\n",
    "    # data_prep.impute_missing(strategy='knn', n_neighbors=15)\n",
    "    # data_prep.data.to_csv(os.path.join(\"data\", \"census\", \"data_pre_processed.csv\"))\n",
    "    # pd.concat([data_prep.x_train, data_prep.y_train, data_prep.d_train], axis=1).to_csv(os.path.join(\"data\", \"census\",\n",
    "    #                                                                                                  \"train.csv\"))\n",
    "    # pd.concat([data_prep.x_test, data_prep.y_test, data_prep.d_test], axis=1).to_csv(os.path.join(\"data\", \"census\",\n",
    "    #                                                                                               \"test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f098c1-2ce9-48c9-9d77-dee664f1ca57",
   "metadata": {},
   "source": [
    "The code below will read in the pre-saved split and pre-processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a65dac4-c90e-42b9-92be-d965724f03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"data\", \"census\", \"data_pre_processed.csv\")\n",
    "train_path = os.path.join(\"data\", \"census\", \"train.csv\")\n",
    "test_path = os.path.join(\"data\", \"census\", \"test.csv\")\n",
    "data_prep = DataPreparator(data=data_path, train_data=train_path, test_data=test_path, features=features,\n",
    "                           dep_var=dep_var, demo_vars=demo_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94beb458-4792-4a38-9ac8-985474069339",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86513c54-7853-4223-bc2f-c3b20edaa9c3",
   "metadata": {},
   "source": [
    "There is new class, MLModelsPipeline, that handles the pipeline for training several ML models. These custom method inherit from sklearn BaseEstimator and operate like sklearn models. Let's start by running cross validation to get the best hyper-parameters settings for our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de27553-176d-4431-b1d0-2886e4f49a5a",
   "metadata": {},
   "source": [
    "Caution: I've randomly set some values for hyper-parameter. This is not an exhaustinve grid search and likley won't results in the best fitting models!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4979e391-e9a6-4be8-a32a-e4e439fec6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid_params = {\n",
    "        'LGR': {'penalty': ['l1', 'l2'], 'C': [0.5, 1.0, 2.0], 'solver': ['liblinear']},\n",
    "        'SVC': {'C': [0.5, 1.0], 'kernel': ['linear', 'poly']},\n",
    "        'KNNC': {'n_neighbors': [5, 50], 'leaf_size': [10, 30], 'p': [1, 2]},\n",
    "        'RFC': {'n_estimators': [100, 200], 'max_depth': [50, 100]},\n",
    "        'MLPC': {'hidden_layer_sizes': [(100,), (20, 50, 20)], 'activation': ['relu', 'logistic']}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da16924-b12c-402a-afe5-2380860d0d6f",
   "metadata": {},
   "source": [
    "Let's set some evaluation metrics for training the models. These should come from the sklearn.metrics classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef1828e1-8478-4ff3-a8be-eff45a03ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    " model_evaluation_metrics = ['accuracy', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763098c-c92b-454e-ab74-4fd76bf3bda5",
   "metadata": {},
   "source": [
    "First, we instantiate the MLModelsPipeline class with our desired parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9912ba7-a16b-44d3-abec-ecba4c38c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = MLModelsPipeline(data_preparator=data_prep, models=model_grid_params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634bb441-df70-4e1b-8a95-fc31f87ebf52",
   "metadata": {},
   "source": [
    "Next, we call the cross_validate_models method within the class to perform k-folds cross validation on our models and get the best hyper-parameters from the ones we tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4189691-6af7-442d-bf7c-eb10f3c50a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Joshua\\anaconda3\\envs\\pragmatic_programming\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation for LGR has completed!\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Cross-validation for SVC has completed!\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "Cross-validation for KNNC has completed!\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Cross-validation for RFC has completed!\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Cross-validation for MLPC has completed!\n"
     ]
    }
   ],
   "source": [
    "pipeline.cross_validate_models(scorer='accuracy', models_search_params=model_grid_params,\n",
    "                                cv=2, return_train_score=True, refit='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100a731-a467-45be-827e-b3126730bbcd",
   "metadata": {},
   "source": [
    "The warnings above may be due to our hyper-paramters settings, or because I'm not running enough iterations. I'm not going to fix it, because the training time will become too long for the purpose of this demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50b393-44c8-4b31-976d-72b84ba0425a",
   "metadata": {},
   "source": [
    "Below are the results for the logistic regression model as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "745eb32d-d33d-4941-8a81-9122f24d3f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085289</td>\n",
       "      <td>0.012710</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.192093e-07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l1', 'solver': 'libline...</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066484</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>4.998446e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065330</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.192093e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1', 'solver': 'libline...</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066954</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>5.960464e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067206</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>3.576279e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 2.0, 'penalty': 'l1', 'solver': 'libline...</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>3.576279e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 2.0, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799432</td>\n",
       "      <td>0.792328</td>\n",
       "      <td>0.79588</td>\n",
       "      <td>0.003552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
       "0       0.085289      0.012710         0.001001    1.192093e-07      0.5   \n",
       "1       0.066484      0.000485         0.001500    4.998446e-04      0.5   \n",
       "2       0.065330      0.000329         0.001000    1.192093e-07      1.0   \n",
       "3       0.066954      0.000045         0.001000    5.960464e-07      1.0   \n",
       "4       0.067206      0.002794         0.002000    3.576279e-07      2.0   \n",
       "5       0.066500      0.000500         0.002000    3.576279e-07      2.0   \n",
       "\n",
       "  param_penalty param_solver  \\\n",
       "0            l1    liblinear   \n",
       "1            l2    liblinear   \n",
       "2            l1    liblinear   \n",
       "3            l2    liblinear   \n",
       "4            l1    liblinear   \n",
       "5            l2    liblinear   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'C': 0.5, 'penalty': 'l1', 'solver': 'libline...           0.792328   \n",
       "1  {'C': 0.5, 'penalty': 'l2', 'solver': 'libline...           0.792328   \n",
       "2  {'C': 1.0, 'penalty': 'l1', 'solver': 'libline...           0.792328   \n",
       "3  {'C': 1.0, 'penalty': 'l2', 'solver': 'libline...           0.792328   \n",
       "4  {'C': 2.0, 'penalty': 'l1', 'solver': 'libline...           0.792328   \n",
       "5  {'C': 2.0, 'penalty': 'l2', 'solver': 'libline...           0.792328   \n",
       "\n",
       "   split1_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.799432          0.79588        0.003552                1   \n",
       "1           0.799432          0.79588        0.003552                1   \n",
       "2           0.799432          0.79588        0.003552                1   \n",
       "3           0.799432          0.79588        0.003552                1   \n",
       "4           0.799432          0.79588        0.003552                1   \n",
       "5           0.799432          0.79588        0.003552                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "0            0.799432            0.792328           0.79588         0.003552  \n",
       "1            0.799432            0.792328           0.79588         0.003552  \n",
       "2            0.799432            0.792328           0.79588         0.003552  \n",
       "3            0.799432            0.792328           0.79588         0.003552  \n",
       "4            0.799432            0.792328           0.79588         0.003552  \n",
       "5            0.799432            0.792328           0.79588         0.003552  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pipeline.cv_results['LGR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a89db7-e05d-4a02-ab1d-449a85952697",
   "metadata": {},
   "source": [
    "Below are the results for the multi-layer perceptrion (neural network) model as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a36932-9582-450d-9020-e9fa1058404c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.344500</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>4.999638e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.779041</td>\n",
       "      <td>0.767424</td>\n",
       "      <td>0.773232</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>3</td>\n",
       "      <td>0.784473</td>\n",
       "      <td>0.763664</td>\n",
       "      <td>0.774068</td>\n",
       "      <td>0.010404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.742500</td>\n",
       "      <td>0.258500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>5.002022e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>(20, 50, 20)</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.785308</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766672</td>\n",
       "      <td>0.780378</td>\n",
       "      <td>0.773525</td>\n",
       "      <td>0.006853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>1.184940e-04</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.753552</td>\n",
       "      <td>0.794334</td>\n",
       "      <td>0.773943</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>2</td>\n",
       "      <td>0.763914</td>\n",
       "      <td>0.790072</td>\n",
       "      <td>0.776993</td>\n",
       "      <td>0.013079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.465968</td>\n",
       "      <td>0.108994</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.192093e-07</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(20, 50, 20)</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.681347</td>\n",
       "      <td>0.795337</td>\n",
       "      <td>0.738342</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>4</td>\n",
       "      <td>0.692378</td>\n",
       "      <td>0.788985</td>\n",
       "      <td>0.740682</td>\n",
       "      <td>0.048304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.344500      0.031500         0.006500    4.999638e-04   \n",
       "1       0.742500      0.258500         0.005500    5.002022e-04   \n",
       "2       0.463000      0.013000         0.005881    1.184940e-04   \n",
       "3       0.465968      0.108994         0.005000    1.192093e-07   \n",
       "\n",
       "  param_activation param_hidden_layer_sizes  \\\n",
       "0             relu                   (100,)   \n",
       "1             relu             (20, 50, 20)   \n",
       "2         logistic                   (100,)   \n",
       "3         logistic             (20, 50, 20)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'activation': 'relu', 'hidden_layer_sizes': (...           0.779041   \n",
       "1  {'activation': 'relu', 'hidden_layer_sizes': (...           0.763079   \n",
       "2  {'activation': 'logistic', 'hidden_layer_sizes...           0.753552   \n",
       "3  {'activation': 'logistic', 'hidden_layer_sizes...           0.681347   \n",
       "\n",
       "   split1_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.767424         0.773232        0.005808                3   \n",
       "1           0.785308         0.774194        0.011115                1   \n",
       "2           0.794334         0.773943        0.020391                2   \n",
       "3           0.795337         0.738342        0.056995                4   \n",
       "\n",
       "   split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "0            0.784473            0.763664          0.774068         0.010404  \n",
       "1            0.766672            0.780378          0.773525         0.006853  \n",
       "2            0.763914            0.790072          0.776993         0.013079  \n",
       "3            0.692378            0.788985          0.740682         0.048304  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pipeline.cv_results['MLPC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e2909d-32bf-491e-bf7d-ad72b0b1aebf",
   "metadata": {},
   "source": [
    "We can call the best_params attribute to get a dictionary of our best fitting hyper-parameters. We will need this next to retrain our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2e76fe9-87d7-487e-b81c-100bdf9c054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LGR': {'C': 0.5, 'penalty': 'l1', 'solver': 'liblinear'}, 'SVC': {'C': 0.5, 'kernel': 'linear'}, 'KNNC': {'leaf_size': 10, 'n_neighbors': 5, 'p': 1}, 'RFC': {'max_depth': 50, 'n_estimators': 200}, 'MLPC': {'activation': 'relu', 'hidden_layer_sizes': (20, 50, 20)}}\n"
     ]
    }
   ],
   "source": [
    " print(pipeline.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde75d30-3f63-4af3-aaae-a1f1ba26c42e",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa9ed8-3ffc-4573-9229-5985a5dbda41",
   "metadata": {},
   "source": [
    "Nest, we call the train_models method to train all of our models on the full training dataset. We pass in the best_params dictionary so that the pipeline know what to set our hyper-parameters to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8bedde9-0ceb-4855-8761-6894731d7204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for model LGR is complete!\n",
      "Training for model SVC is complete!\n",
      "Training for model KNNC is complete!\n",
      "Training for model RFC is complete!\n",
      "Training for model MLPC is complete!\n"
     ]
    }
   ],
   "source": [
    "pipeline.train_models(model_specs=pipeline.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92db2e9-cbf9-4e6d-b230-b38d6ec9776d",
   "metadata": {},
   "source": [
    "We just trained 5 machine learning models with a single line of code :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f394491-5439-4d2b-a8c2-5611af27e048",
   "metadata": {},
   "source": [
    "# Evaluate Models Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62921122-97eb-49c7-9b01-43cb0777e8f3",
   "metadata": {},
   "source": [
    "Now, let's evaluate how our models performed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b0a7086-6462-4db7-9fa9-ae50f9bba545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for model LGR is complete!\n",
      "Evaluation for model SVC is complete!\n",
      "Evaluation for model KNNC is complete!\n",
      "Evaluation for model RFC is complete!\n",
      "Evaluation for model MLPC is complete!\n",
      "                accuracy_score  recall_score\n",
      "LGR      train        0.844518      0.549347\n",
      "         test         0.849519      0.555815\n",
      "SVC      train        0.792286      0.277682\n",
      "         test         0.797857      0.271058\n",
      "KNNC     train        0.832609      0.441541\n",
      "         test         0.777247      0.301078\n",
      "RFC      train        0.999708      0.999312\n",
      "         test         0.838668      0.609443\n",
      "MLPC     train        0.784431      0.131018\n",
      "         test         0.787962      0.114835\n",
      "ensemble train        0.843390      0.373281\n",
      "         test         0.825974      0.299038\n"
     ]
    }
   ],
   "source": [
    "perf_results = pipeline.evaluate_performance(scorer=['accuracy_score', 'recall_score'], ensemble='classifier')\n",
    "print(perf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b3291-f581-463f-8252-c5a74fd3ff7f",
   "metadata": {},
   "source": [
    "# Evaluate Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5b25a4-a018-4d0a-94ad-4e9c01891584",
   "metadata": {},
   "source": [
    "We can also use the pipeline to evaluate the fairness of our model. It's best to use the term \"fairness\" here, because \"bias\" already has a specific meaning when training ML models. The Bias-Variance trade-off refers to when models are too simplistic in their training, which causes errors. Its somewhat similar to validity and reliability that we talk about in Psychometrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66f4b92c-4742-47ec-b13d-d3ca73dbb996",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dict = {\n",
    "        'race': {'White': ['Black', 'Other']},\n",
    "        'gender': {'Male': ['Female']}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c49fe-ff42-445a-8d21-be8dcef0738f",
   "metadata": {},
   "source": [
    "We use the dictionary above the state what demographic variable we are testing and the pairwise comparisons between groups for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bdc23d3-5f8e-4b63-9756-927935c2e30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      White_Black  White_Other  Male_Female\n",
      "LGR      0.425532     0.375307     0.296637\n",
      "SVC      0.470609     0.359962     0.513184\n",
      "KNNC     0.634699     0.524219     0.483059\n",
      "RFC      0.481022     0.368568     0.369087\n",
      "MLPC     0.604112     0.375982     0.535538\n"
     ]
    }
   ],
   "source": [
    "fairness_results = pipeline.evaluate_fairness(scorer='disparate_impact', comparison_dict=comparison_dict)\n",
    "print(fairness_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004a158-37ef-409f-b90e-ca36278ecfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pragmatic_programming)",
   "language": "python",
   "name": "pragmatic_programming"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
